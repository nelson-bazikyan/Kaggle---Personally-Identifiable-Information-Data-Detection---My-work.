{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a620e68e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:48:24.821230Z",
     "iopub.status.busy": "2024-02-24T03:48:24.820777Z",
     "iopub.status.idle": "2024-02-24T03:48:29.124597Z",
     "shell.execute_reply": "2024-02-24T03:48:29.123087Z"
    },
    "papermill": {
     "duration": 4.316222,
     "end_time": "2024-02-24T03:48:29.127619",
     "exception": false,
     "start_time": "2024-02-24T03:48:24.811397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('/kaggle/input/pii-detection-removal-from-educational-data/train.json', 'r') as file:\n",
    "    data_train = json.load(file)\n",
    "\n",
    "with open('/kaggle/input/pii-detection-removal-from-educational-data/test.json', 'r') as file:\n",
    "    data_test = json.load(file)\n",
    "\n",
    "common_words_filter = pd.read_csv('/kaggle/input/for-pii-detection/common_words_except_names.csv')\n",
    "words_to_filter = 50000\n",
    "common_filt = common_words_filter['word'].values.tolist()[:words_to_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18445e0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:48:29.141521Z",
     "iopub.status.busy": "2024-02-24T03:48:29.141128Z",
     "iopub.status.idle": "2024-02-24T03:48:29.396666Z",
     "shell.execute_reply": "2024-02-24T03:48:29.395448Z"
    },
    "papermill": {
     "duration": 0.265514,
     "end_time": "2024-02-24T03:48:29.399379",
     "exception": false,
     "start_time": "2024-02-24T03:48:29.133865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "strings = []\n",
    "test_strings = []\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "    strings.append(' '.join(data_train[i]['tokens']))\n",
    "\n",
    "for i in range(len(data_test)):\n",
    "    test_strings.append(' '.join(data_test[i]['tokens']))\n",
    "\n",
    "combined_strings = strings + test_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ceff74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:48:29.413705Z",
     "iopub.status.busy": "2024-02-24T03:48:29.412939Z",
     "iopub.status.idle": "2024-02-24T03:48:35.357609Z",
     "shell.execute_reply": "2024-02-24T03:48:35.356317Z"
    },
    "papermill": {
     "duration": 5.955032,
     "end_time": "2024-02-24T03:48:35.360403",
     "exception": false,
     "start_time": "2024-02-24T03:48:29.405371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=common_filt)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(combined_strings)\n",
    "tfidf_array = tfidf_vectors.toarray()\n",
    "\n",
    "tfidf_array_train = tfidf_array[:len(data_train)]\n",
    "tfidf_array_test = tfidf_array[len(data_train):]\n",
    "\n",
    "term_indices = []\n",
    "for i in range(len(data_train)):\n",
    "    tfidf_values = tfidf_array_train[i]\n",
    "    indices = np.argwhere(tfidf_values > 0.05).flatten()\n",
    "    term_indices.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a1d9e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:48:35.374563Z",
     "iopub.status.busy": "2024-02-24T03:48:35.374137Z",
     "iopub.status.idle": "2024-02-24T03:49:53.218380Z",
     "shell.execute_reply": "2024-02-24T03:49:53.217189Z"
    },
    "papermill": {
     "duration": 77.854742,
     "end_time": "2024-02-24T03:49:53.221321",
     "exception": false,
     "start_time": "2024-02-24T03:48:35.366579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train_lower = [np.char.lower(np.array(doc['tokens'])) for doc in data_train]\n",
    "inspect_list = []\n",
    "\n",
    "for doc_index, doc in enumerate(data_train_lower):\n",
    "    terms_to_inspect = set(tfidf_vectorizer.get_feature_names_out()[term_indices[doc_index]])\n",
    "    indices_to_inspect = [i for i, term in enumerate(doc) if term in terms_to_inspect]\n",
    "    inspect_list.append(indices_to_inspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94826fa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:49:53.236219Z",
     "iopub.status.busy": "2024-02-24T03:49:53.235771Z",
     "iopub.status.idle": "2024-02-24T03:49:53.363559Z",
     "shell.execute_reply": "2024-02-24T03:49:53.362078Z"
    },
    "papermill": {
     "duration": 0.138556,
     "end_time": "2024-02-24T03:49:53.366384",
     "exception": false,
     "start_time": "2024-02-24T03:49:53.227828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_inspect = []\n",
    "word_inspect = []\n",
    "\n",
    "for i in range(len(inspect_list)):\n",
    "    num_inspect.append([x for x in (inspect_list[i]) if data_train[i]['tokens'][x].isdigit()])\n",
    "    word_inspect.append([x for x in (inspect_list[i]) if not data_train[i]['tokens'][x].isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc8d35c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:49:53.380428Z",
     "iopub.status.busy": "2024-02-24T03:49:53.379773Z",
     "iopub.status.idle": "2024-02-24T03:49:55.350766Z",
     "shell.execute_reply": "2024-02-24T03:49:55.349692Z"
    },
    "papermill": {
     "duration": 1.981102,
     "end_time": "2024-02-24T03:49:55.353579",
     "exception": false,
     "start_time": "2024-02-24T03:49:53.372477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NN_inputs = []\n",
    "for docnum in range(len(word_inspect)):\n",
    "    for index in word_inspect[docnum]:\n",
    "        info = {}\n",
    "        tokens = data_train[docnum]['tokens']\n",
    "        info['Doc Index'] = docnum\n",
    "        info['Token Index'] = index\n",
    "        info['Token'] = tokens[index]\n",
    "        doclen = len(tokens)\n",
    "        info['Word Score'] = float(tfidf_array_train[docnum, tfidf_vectorizer.vocabulary_.get(tokens[index].lower())])\n",
    "        info['Doc Distance'] = float(max((doclen-index)/doclen/2, index/doclen/2))\n",
    "        try:\n",
    "            words = [tokens[index-2].lower(), tokens[index-1].lower(), tokens[index+1].lower(), tokens[index+2].lower()]\n",
    "            word_indices = [tfidf_vectorizer.vocabulary_.get(word) for word in words]\n",
    "            scores = []\n",
    "            for word_index in word_indices:\n",
    "                if word_index == None:\n",
    "                    scores.append(0)\n",
    "                else:\n",
    "                    scores.append(tfidf_array_train[docnum, word_index])\n",
    "            info['Surrounding Scores'] = scores\n",
    "        except:\n",
    "            info['Surrounding Scores'] = [0, 0, 0, 0]\n",
    "        correct = data_train[docnum]['labels'][index]\n",
    "        if correct == 'O':\n",
    "             info['Correct'] = 0\n",
    "        else:\n",
    "             info['Correct'] = 1\n",
    "        NN_inputs.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e2cae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:49:55.368174Z",
     "iopub.status.busy": "2024-02-24T03:49:55.367785Z",
     "iopub.status.idle": "2024-02-24T03:52:33.854877Z",
     "shell.execute_reply": "2024-02-24T03:52:33.853683Z"
    },
    "papermill": {
     "duration": 158.658673,
     "end_time": "2024-02-24T03:52:34.018519",
     "exception": false,
     "start_time": "2024-02-24T03:49:55.359846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 03:49:57.675287: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-24 03:49:57.675410: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-24 03:49:57.834871: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3239/3239 [==============================] - 8s 2ms/step - loss: 0.0210 - mae: 0.0618 - val_loss: 0.0181 - val_mae: 0.0380\n",
      "Epoch 2/15\n",
      "3239/3239 [==============================] - 7s 2ms/step - loss: 0.0174 - mae: 0.0390 - val_loss: 0.0174 - val_mae: 0.0411\n",
      "Epoch 3/15\n",
      "3239/3239 [==============================] - 6s 2ms/step - loss: 0.0157 - mae: 0.0436 - val_loss: 0.0156 - val_mae: 0.0357\n",
      "Epoch 4/15\n",
      "3239/3239 [==============================] - 6s 2ms/step - loss: 0.0149 - mae: 0.0398 - val_loss: 0.0150 - val_mae: 0.0433\n",
      "Epoch 5/15\n",
      "3239/3239 [==============================] - 6s 2ms/step - loss: 0.0145 - mae: 0.0384 - val_loss: 0.0146 - val_mae: 0.0412\n",
      "Epoch 6/15\n",
      "3239/3239 [==============================] - 6s 2ms/step - loss: 0.0141 - mae: 0.0369 - val_loss: 0.0141 - val_mae: 0.0349\n",
      "Epoch 7/15\n",
      "3239/3239 [==============================] - 6s 2ms/step - loss: 0.0136 - mae: 0.0348 - val_loss: 0.0136 - val_mae: 0.0351\n",
      "Epoch 8/15\n",
      "3239/3239 [==============================] - 7s 2ms/step - loss: 0.0131 - mae: 0.0330 - val_loss: 0.0131 - val_mae: 0.0321\n",
      "Epoch 9/15\n",
      "3239/3239 [==============================] - 6s 2ms/step - loss: 0.0127 - mae: 0.0310 - val_loss: 0.0126 - val_mae: 0.0292\n",
      "Epoch 10/15\n",
      "3239/3239 [==============================] - 7s 2ms/step - loss: 0.0123 - mae: 0.0289 - val_loss: 0.0123 - val_mae: 0.0325\n",
      "Epoch 11/15\n",
      "3239/3239 [==============================] - 7s 2ms/step - loss: 0.0120 - mae: 0.0275 - val_loss: 0.0120 - val_mae: 0.0290\n",
      "Epoch 12/15\n",
      "3239/3239 [==============================] - 7s 2ms/step - loss: 0.0117 - mae: 0.0259 - val_loss: 0.0117 - val_mae: 0.0246\n",
      "Epoch 13/15\n",
      "3239/3239 [==============================] - 7s 2ms/step - loss: 0.0115 - mae: 0.0247 - val_loss: 0.0116 - val_mae: 0.0226\n",
      "Epoch 14/15\n",
      "3239/3239 [==============================] - 7s 2ms/step - loss: 0.0114 - mae: 0.0237 - val_loss: 0.0114 - val_mae: 0.0228\n",
      "Epoch 15/15\n",
      "3239/3239 [==============================] - 6s 2ms/step - loss: 0.0112 - mae: 0.0227 - val_loss: 0.0112 - val_mae: 0.0236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ff18ab1aaa0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "\n",
    "X = np.array([[sample['Word Score']] + [sample['Doc Distance']] + sample['Surrounding Scores'] for sample in NN_inputs])\n",
    "Y = np.array([sample['Correct'] for sample in NN_inputs])\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "model_NN = keras.Sequential()\n",
    "model_NN.add(keras.layers.Input(shape=(6,)))\n",
    "model_NN.add(keras.layers.Dense(24, activation='sigmoid'))\n",
    "model_NN.add(keras.layers.Dense(12, activation='sigmoid'))\n",
    "model_NN.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model_NN.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model_NN.fit(X_train, Y_train, epochs=15, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2004f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:34.405470Z",
     "iopub.status.busy": "2024-02-24T03:52:34.405049Z",
     "iopub.status.idle": "2024-02-24T03:52:34.475221Z",
     "shell.execute_reply": "2024-02-24T03:52:34.473523Z"
    },
    "papermill": {
     "duration": 0.29866,
     "end_time": "2024-02-24T03:52:34.477795",
     "exception": false,
     "start_time": "2024-02-24T03:52:34.179135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/788080326.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_tree_df['Class'] = train_tree_df['Class'].map(class_map)\n"
     ]
    }
   ],
   "source": [
    "TREE_inputs = []\n",
    "for docnum in range(len(num_inspect)):\n",
    "    for index in num_inspect[docnum]:\n",
    "        info = {}\n",
    "        tokens = data_train[docnum]['tokens']\n",
    "        info['Doc Index'] = docnum\n",
    "        info['Token Index'] = index\n",
    "        info['Token'] = int(tokens[index])\n",
    "        info['Number Score'] = float(tfidf_array_train[docnum, tfidf_vectorizer.vocabulary_.get(tokens[index])])\n",
    "        info['Class'] = data_train[docnum]['labels'][index]\n",
    "        TREE_inputs.append(info)\n",
    "\n",
    "tree_df = pd.DataFrame(TREE_inputs)\n",
    "train_tree_df = tree_df[['Token', 'Number Score', 'Class']]\n",
    "\n",
    "class_map = {'B-ID_NUM': 0, 'B-STREET_ADDRESS': 1, 'I-ID_NUM': 0, 'I-PHONE_NUM': 3, 'I-STREET_ADDRESS': 4, 'O': 5}\n",
    "train_tree_df['Class'] = train_tree_df['Class'].map(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4528dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:34.803223Z",
     "iopub.status.busy": "2024-02-24T03:52:34.802801Z",
     "iopub.status.idle": "2024-02-24T03:52:44.061216Z",
     "shell.execute_reply": "2024-02-24T03:52:44.060277Z"
    },
    "papermill": {
     "duration": 9.424147,
     "end_time": "2024-02-24T03:52:44.063963",
     "exception": false,
     "start_time": "2024-02-24T03:52:34.639816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpey3h4_e7 as temporary training directory\n",
      "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:06.885861. Found 7336 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.035089\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-02-24 03:52:42.2742 UTC kernel.cc:1233] Loading model from path /tmp/tmpey3h4_e7/model/ with prefix 8d13e4ae3f154937\n",
      "[INFO 24-02-24 03:52:42.2764 UTC decision_forest.cc:660] Model loaded with 1 root(s), 3 node(s), and 1 input feature(s).\n",
      "[INFO 24-02-24 03:52:42.2766 UTC abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n",
      "[INFO 24-02-24 03:52:42.2768 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ff1795c31f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "input_features = [tfdf.keras.FeatureUsage(name='Number'), tfdf.keras.FeatureUsage(name='tfidf')]\n",
    "\n",
    "model_TREE = tfdf.keras.CartModel()\n",
    "model_TREE.compile(metrics=['accuracy'])\n",
    "\n",
    "dataset = tfdf.keras.pd_dataframe_to_tf_dataset(train_tree_df, label='Class')\n",
    "model_TREE.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0b6023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:44.392728Z",
     "iopub.status.busy": "2024-02-24T03:52:44.392018Z",
     "iopub.status.idle": "2024-02-24T03:52:44.398594Z",
     "shell.execute_reply": "2024-02-24T03:52:44.397508Z"
    },
    "papermill": {
     "duration": 0.174274,
     "end_time": "2024-02-24T03:52:44.400958",
     "exception": false,
     "start_time": "2024-02-24T03:52:44.226684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_term_indices = []\n",
    "for i in range(len(data_test)):\n",
    "    tfidf_values = tfidf_array_test[i]\n",
    "    indices = np.argwhere(tfidf_values > 0.05).flatten()\n",
    "    test_term_indices.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "058ee1f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:44.730606Z",
     "iopub.status.busy": "2024-02-24T03:52:44.730157Z",
     "iopub.status.idle": "2024-02-24T03:52:44.858290Z",
     "shell.execute_reply": "2024-02-24T03:52:44.857142Z"
    },
    "papermill": {
     "duration": 0.296359,
     "end_time": "2024-02-24T03:52:44.860900",
     "exception": false,
     "start_time": "2024-02-24T03:52:44.564541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_test_lower = [np.char.lower(np.array(doc['tokens'])) for doc in data_test]\n",
    "test_inspect_list = []\n",
    "\n",
    "for doc_index, doc_tokens in enumerate(data_test_lower):\n",
    "    terms_to_inspect = set(tfidf_vectorizer.get_feature_names_out()[test_term_indices[doc_index]])\n",
    "    indices_to_inspect = [i for i, term in enumerate(doc_tokens) if term in terms_to_inspect]\n",
    "    test_inspect_list.append(indices_to_inspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "464557cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:45.193094Z",
     "iopub.status.busy": "2024-02-24T03:52:45.192659Z",
     "iopub.status.idle": "2024-02-24T03:52:45.199881Z",
     "shell.execute_reply": "2024-02-24T03:52:45.198798Z"
    },
    "papermill": {
     "duration": 0.173839,
     "end_time": "2024-02-24T03:52:45.202070",
     "exception": false,
     "start_time": "2024-02-24T03:52:45.028231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_num_inspect = []\n",
    "test_word_inspect = []\n",
    "\n",
    "for i in range(len(test_inspect_list)):\n",
    "    test_num_inspect.append([x for x in (test_inspect_list[i]) if data_test[i]['tokens'][x].isdigit()])\n",
    "    test_word_inspect.append([x for x in (test_inspect_list[i]) if not data_test[i]['tokens'][x].isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdbe53aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:45.530989Z",
     "iopub.status.busy": "2024-02-24T03:52:45.530322Z",
     "iopub.status.idle": "2024-02-24T03:52:45.543805Z",
     "shell.execute_reply": "2024-02-24T03:52:45.542527Z"
    },
    "papermill": {
     "duration": 0.182061,
     "end_time": "2024-02-24T03:52:45.546278",
     "exception": false,
     "start_time": "2024-02-24T03:52:45.364217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NN_test_inputs = []\n",
    "for docnum in range(len(test_word_inspect)):\n",
    "    for index in test_word_inspect[docnum]:\n",
    "        info = {}\n",
    "        tokens = data_test[docnum]['tokens']\n",
    "        info['Doc Index'] = data_test[docnum]['document']\n",
    "        info['Token Index'] = index\n",
    "        info['Token'] = tokens[index]\n",
    "        doclen = len(tokens)\n",
    "        info['Word Score'] = float(tfidf_array_test[docnum, tfidf_vectorizer.vocabulary_.get(tokens[index].lower())])\n",
    "        info['Doc Distance'] = float(max((doclen-index)/doclen/2, index/doclen/2))\n",
    "        try:\n",
    "            words = [tokens[index-2].lower(), tokens[index-1].lower(), tokens[index+1].lower(), tokens[index+2].lower()]\n",
    "            word_indices = [tfidf_vectorizer.vocabulary_.get(word) for word in words]\n",
    "            scores = []\n",
    "            for word_index in word_indices:\n",
    "                if word_index == None:\n",
    "                    scores.append(0)\n",
    "                else:\n",
    "                    scores.append(tfidf_array_test[docnum, word_index])\n",
    "            info['Surrounding Scores'] = scores\n",
    "        except:\n",
    "            info['Surrounding Scores'] = [0, 0, 0, 0]\n",
    "        NN_test_inputs.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53633a9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:45.876411Z",
     "iopub.status.busy": "2024-02-24T03:52:45.875949Z",
     "iopub.status.idle": "2024-02-24T03:52:45.885256Z",
     "shell.execute_reply": "2024-02-24T03:52:45.884424Z"
    },
    "papermill": {
     "duration": 0.175393,
     "end_time": "2024-02-24T03:52:45.887284",
     "exception": false,
     "start_time": "2024-02-24T03:52:45.711891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TREE_test_inputs = []\n",
    "for docnum in range(len(test_num_inspect)):\n",
    "    for index in test_num_inspect[docnum]:\n",
    "        info = {}\n",
    "        tokens = data_test[docnum]['tokens']\n",
    "        info['Doc Index'] = data_test[docnum]['document']\n",
    "        info['Token Index'] = index\n",
    "        info['Token'] = int(tokens[index])\n",
    "        info['Number Score'] = float(tfidf_array_test[docnum, tfidf_vectorizer.vocabulary_.get(tokens[index])])\n",
    "        TREE_test_inputs.append(info)\n",
    "\n",
    "tree_test_df = pd.DataFrame(TREE_test_inputs)\n",
    "tree_predict_df = tree_test_df[['Token', 'Number Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c8cf97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:46.217244Z",
     "iopub.status.busy": "2024-02-24T03:52:46.216495Z",
     "iopub.status.idle": "2024-02-24T03:52:46.457423Z",
     "shell.execute_reply": "2024-02-24T03:52:46.456253Z"
    },
    "papermill": {
     "duration": 0.408746,
     "end_time": "2024-02-24T03:52:46.459989",
     "exception": false,
     "start_time": "2024-02-24T03:52:46.051243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([[sample['Word Score']] + [sample['Doc Distance']] + sample['Surrounding Scores'] for sample in NN_test_inputs])\n",
    "\n",
    "NN_predictions = model_NN.predict(X_test)\n",
    "NN_test_df = pd.DataFrame(NN_test_inputs)\n",
    "NN_test_df['Pred'] = NN_predictions\n",
    "NN_test_df['Correct'] = NN_test_df['Pred'] > 0.55\n",
    "\n",
    "NN_test_df['Correct'] = NN_test_df.groupby(['Doc Index', 'Token'])['Correct'].transform(lambda x: x.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "440b7c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:46.787659Z",
     "iopub.status.busy": "2024-02-24T03:52:46.787224Z",
     "iopub.status.idle": "2024-02-24T03:52:46.798809Z",
     "shell.execute_reply": "2024-02-24T03:52:46.797472Z"
    },
    "papermill": {
     "duration": 0.17797,
     "end_time": "2024-02-24T03:52:46.801440",
     "exception": false,
     "start_time": "2024-02-24T03:52:46.623470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_map = {True: 'B-NAME_STUDENT', False: 'O'}\n",
    "NN_test_df['Label'] = NN_test_df['Correct'].map(label_map)\n",
    "\n",
    "mask = NN_test_df['Label'] != 'O'\n",
    "mask2 = NN_test_df['Label'].shift(fill_value='O') == 'B-NAME_STUDENT'\n",
    "mask3 = NN_test_df['Doc Index'] == NN_test_df['Doc Index'].shift(fill_value='')\n",
    "mask4 = NN_test_df['Token Index'].shift(fill_value=0) == NN_test_df['Token Index'] - 1\n",
    "\n",
    "NN_test_df.loc[mask & mask2 & mask3 & mask4, 'Label'] = 'I-NAME_STUDENT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d033d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:47.132072Z",
     "iopub.status.busy": "2024-02-24T03:52:47.131660Z",
     "iopub.status.idle": "2024-02-24T03:52:47.188063Z",
     "shell.execute_reply": "2024-02-24T03:52:47.187213Z"
    },
    "papermill": {
     "duration": 0.224662,
     "end_time": "2024-02-24T03:52:47.190401",
     "exception": false,
     "start_time": "2024-02-24T03:52:46.965739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some of the feature names have been changed automatically to be compatible with SavedModels because fix_feature_names=True.\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(tree_predict_df)\n",
    "predictions_tree = model_TREE.predict(predict_dataset)\n",
    "predictions_tree = predictions_tree.argmax(axis=1)\n",
    "\n",
    "tree_test_df['Class'] = predictions_tree\n",
    "inv_class_map = {num: clas for clas, num in class_map.items()}\n",
    "tree_test_df['Class'] = tree_test_df['Class'].map(inv_class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d484921c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:47.522597Z",
     "iopub.status.busy": "2024-02-24T03:52:47.521696Z",
     "iopub.status.idle": "2024-02-24T03:52:47.533009Z",
     "shell.execute_reply": "2024-02-24T03:52:47.532090Z"
    },
    "papermill": {
     "duration": 0.179322,
     "end_time": "2024-02-24T03:52:47.535555",
     "exception": false,
     "start_time": "2024-02-24T03:52:47.356233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = ['document', 'token', 'label']\n",
    "NN_test_df = NN_test_df.rename(columns={'Doc Index': 'document', 'Token Index': 'token', 'Label': 'label'})\n",
    "NN_submission_df = NN_test_df[columns]\n",
    "tree_test_df = tree_test_df.rename(columns={'Doc Index': 'document', 'Token Index': 'token', 'Class': 'label'})\n",
    "tree_submission_df = tree_test_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc6b518c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T03:52:47.871317Z",
     "iopub.status.busy": "2024-02-24T03:52:47.870325Z",
     "iopub.status.idle": "2024-02-24T03:52:47.887395Z",
     "shell.execute_reply": "2024-02-24T03:52:47.886318Z"
    },
    "papermill": {
     "duration": 0.187276,
     "end_time": "2024-02-24T03:52:47.890331",
     "exception": false,
     "start_time": "2024-02-24T03:52:47.703055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df = pd.concat([NN_submission_df, tree_submission_df])\n",
    "submission_df.reset_index(drop=True, inplace=True)\n",
    "submission_df.sort_values(by=['document', 'token'], inplace=True)\n",
    "submission_df = submission_df[submission_df['label'] != 'O']\n",
    "submission_df.reset_index(drop=True, inplace=True)\n",
    "submission_df['row_id'] = submission_df.index\n",
    "submission_df = submission_df[['row_id', 'document', 'token', 'label']]\n",
    "\n",
    "submission_df.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 4461121,
     "sourceId": 7652462,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 269.285167,
   "end_time": "2024-02-24T03:52:51.056606",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-24T03:48:21.771439",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
